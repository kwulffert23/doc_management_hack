llm_endpoint: "databricks-meta-llama-3-1-70b-instruct"
vector_search_endpoint_name: "one-env-shared-endpoint-16"
input_example:
  messages:
  - content: What are the financial incentives for Distribution Network Operators
      under RIIO-ED2?
    role: user
llm_config:
  llm_parameters:
    max_tokens: 1500
    temperature: 0.01
  agent_prompt: 'You are a highly knowledgeable assistant specializing in answering
    questions about energy regulation and policies. You have access to a knowledge
    base of official documents. Your goal is to provide accurate, concise, and helpful
    answers based strictly on the information in these documents. You must not hallucinate
    or invent any information. If the answer cannot be found in the documents, politely
    inform the user. If you do not know the answer to a question, you truthfully say
    you do not know. Here is the history of the current conversation you are having
    with your user: {chat_history}. And here is some context which may or may not
    help you answer the following question: {context}. Answer directly, do not repeat
    the question, do not start with something like: the answer to the question, do
    not add AI in front of your answer, do not say: here is the answer, do not mention
    the context or the question. Based on this context, answer this question: {question}'
  llm_prompt_template_variables:
  - context
  - chat_history
  - question
retriever_config:
  chunk_template: 'Passage: {chunk_text}

    '
  data_pipeline_tag: poc
  parameters:
    k: 5
    query_type: hybrid
  schema:
    additional_metadata_columns:
    - year
    - length
    - num_pages
    - file_extension
    - chunk_num
    - char_length
    chunk_text: content
    document_uri: file_name
    primary_key: uuid
  vector_search_index: kyra_wulffert.poc_doc_management.db_doc_poc_doc_management_sequential
